{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CNN Implementation  #TODO EDIT below process\n",
    "Covers question 3 from the assignment. Below are the steps it covers \n",
    "1. Downloads dataset from torchvision.datasets\n",
    "2. Pre-process all the input data and Normalise the data.\n",
    "3. Splits train-dataset into training and validation sets\n",
    "4. Train the models using train-dataset using forward and backward pass with different hyperparameters \n",
    "5. Evaluate the model using test data on all the trained models "
   ],
   "id": "72236f48f1096391"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T14:04:03.747628Z",
     "start_time": "2024-11-13T14:04:03.727984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "from data_preparation import pre_process_dataset, prepare_dataset_dict\n",
    "from mlp import compare_training_and_validation_loss\n",
    "from cnn import cnn_test, cnn_train, load_data_to_cnn\n"
   ],
   "id": "5b7d602f9049156c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T14:04:04.385887Z",
     "start_time": "2024-11-13T14:04:04.266720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data preparation for CNN\n",
    "dataset_d= prepare_dataset_dict()\n",
    "cnn_dataset_dict = pre_process_dataset(dataset_d, flatten=False)\n",
    "torch_datasets = load_data_to_cnn(cnn_dataset_dict)"
   ],
   "id": "dbbbcd788aa1efcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------TRAIN DATA---------------------------------\n",
      "Available Training dataset contains 60,000 images.\n",
      "Each image is of size 28x28\n",
      "Each image is labelled one of: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "Each image pixel values are between 0 and 255\n",
      "---------------------------------------------------------------------\n",
      "------------------------- TRAIN DATA After Split -----------------------\n",
      "Final Training dataset shape: (52800, ',') images of 28x28\n",
      "Final Validation dataset shape: (7200, ',') images of 28x28\n",
      "---------------------------------------------------------------------\n",
      "------------------------- TEST DATA ---------------------------------\n",
      "Test dataset contains 10,000 images.\n",
      "Each image is of size 28x28\n",
      "Each image is labelled one of: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "Each image pixel values are between 0 and 255\n",
      "---------------------------------------------------------------------\n",
      "--------------------------- Train Data Processed-----------------------------------\n",
      "Normalised `train` from (min,max) of (np.uint8(0), np.uint8(255)) to (np.float64(0.0), np.float64(1.0))\n",
      "Added One hot encoded label arrays for `train`\n",
      "--------------------------- Test Data Processed-----------------------------------\n",
      "Normalised `test` from (min,max) of (np.uint8(0), np.uint8(255)) to (np.float64(0.0), np.float64(1.0))\n",
      "Added One hot encoded label arrays for `test`\n",
      "--------------------------- Val Data Processed-----------------------------------\n",
      "Normalised `val` from (min,max) of (np.uint8(0), np.uint8(255)) to (np.float64(0.0), np.float64(1.0))\n",
      "Added One hot encoded label arrays for `val`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 164.84it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#CNN__32_64_128_256_kernel_3__mlp__layers__128_64_32__lr_0.01__epoch_50\n",
    "input_size = 256  # Flattened size from the CNN feature map output\n",
    "hidden_layers = [128, 64, 32]  # Full connected layers for classification\n",
    "num_epochs = 100\n",
    "learning_rate = 0.1\n",
    "activation_function = \"relu\"\n",
    "initialisation_function = \"He\"\n",
    "cnn_trained_dict, mlp_model, cnn_model = cnn_train(torch_datasets, input_size, hidden_layers, learning_rate, num_epochs, activation_function,\n",
    "          initialisation_function)"
   ],
   "id": "8eb7750822715c49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cnn_trained_dict['model_name'] = mlp_model.model_name\n",
    "compare_training_and_validation_loss(cnn_trained_dict)"
   ],
   "id": "fa4eef6185fa6d3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cnn_test(cnn_dataset_dict, mlp_model, cnn_model) ",
   "id": "8a7a56749e7881fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
